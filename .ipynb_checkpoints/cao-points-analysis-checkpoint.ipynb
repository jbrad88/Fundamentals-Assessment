{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAO Points Analysis\n",
    "Jody Bradley - G00387878\n",
    "***\n",
    "## Introduction\n",
    "We have been tasked with creating a Jupyter notebook which contains the following:\n",
    "\n",
    "* A clear and concise overview of how to load CAO points information from the CAO website into a pandas data frame.\n",
    "* A detailed comparison of CAO points in 2019, 2020, and 2021 using the functionality in pandas.\n",
    "* Appropriate plots and other visualisations to enhance your notebook for viewers.\n",
    "\n",
    "## Web Scraping\n",
    "\"Web Scraping\" allows us to pull a large amount of data from a website in a quick and efficient manner. The purpose of this Jupyter notebook is to provide a clear and concise overview of how to load CAO points information from the CAO website into a pandas data frame.\n",
    "\n",
    "## Importing required packages\n",
    "We will need to import a number of packages to help us with this task.\n",
    "\n",
    "#### Regular Expression\n",
    "A Regular Expression is a sequence of characters that forms a search pattern. It can be used to check if a string contains a specific search patter [1]\n",
    "\n",
    "#### Requests\n",
    "The requests module allows us to send a HTTP request using Python. It returns a Response Object with all the response data (content, encoding, status, etc.) [2]\n",
    "\n",
    "#### DateTime\n",
    "This module allows us to work with dates as data objects [3].\n",
    "\n",
    "#### Pandas\n",
    "Pandas is a Python library used for working with data sets. It has functions for analyzing, cleaning, exploring and manipulating data [4].\n",
    "\n",
    "#### Urllib\n",
    "The Urllib package is used for fetching and handling URLs [5]. We'll be using urllib.request for downloading.\n",
    "\n",
    "#### Seaborn \n",
    "Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'vq' from partially initialized module 'scipy.cluster' (most likely due to a circular import) (C:\\Users\\jodyb\\anaconda3\\lib\\site-packages\\scipy\\cluster\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e3ad17160d4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# For plotting style.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcategorical\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# noqa: F401,F403\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# noqa: F401,F403\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmatrix\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# noqa: F401,F403\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmiscplot\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# noqa: F401,F403\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0maxisgrid\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# noqa: F401,F403\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\matrix.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhierarchy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\cluster\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0m__all__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'vq'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'hierarchy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhierarchy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_testutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPytestTester\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'vq' from partially initialized module 'scipy.cluster' (most likely due to a circular import) (C:\\Users\\jodyb\\anaconda3\\lib\\site-packages\\scipy\\cluster\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# Convenient HTTP requests.\n",
    "import requests as rq\n",
    "\n",
    "# Regular expressions.\n",
    "import re\n",
    "\n",
    "# Dates and times.\n",
    "import datetime as dt\n",
    "\n",
    "# Data frames.\n",
    "import pandas as pd\n",
    "\n",
    "# For downloading.\n",
    "import urllib.request as urlrq\n",
    "\n",
    "# For plotting.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For plotting style.\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the current date and time\n",
    "\n",
    "We'll be using the datetime function to give our saved files a unique name when scraping the data from the CAO website. First, let's get the current date and time and format it as a string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current date and time.\n",
    "now = dt.datetime.now()\n",
    "\n",
    "# Format as a string.\n",
    "nowstr = now.strftime('%Y%m%d_%H%M%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2021 Points\n",
    "\n",
    "***\n",
    "In this section we will download the 2021 data from the CAO website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the CAO points URL [6]:\n",
    "#resp = rq.get('http://www2.cao.ie/points/l8.php') \n",
    "\n",
    "# Have a quick peek. 200 means OK.\n",
    "#resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Save original data set\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a file path for the original data.\n",
    "#pathhtml = 'data/cao2021_' + nowstr + '.html'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Error on server**\n",
    "\n",
    "\n",
    "Technically, the server says we should decode as per:\n",
    "    \n",
    "```\n",
    "Content-Type: text/html; charset=iso-8859-1\n",
    "```\n",
    "\n",
    "However, one line uses \\x96 which isn't defined in iso-8859-1.\n",
    "\n",
    "Therefore we use the similar decoding standard cp1252, which is very similar but includes #x96."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The server uses the wrong encoding, fix it.\n",
    "#original_encoding = resp.encoding\n",
    "\n",
    "# Change to cp1252.\n",
    "#resp.encoding = 'cp1252'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the original html file.\n",
    "#with open(pathhtml, 'w') as f:\n",
    "#    f.write(resp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Use regular expressions to select lines we want\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the regular expression for matching lines.\n",
    "#re_course = re.compile(r'([A-Z]{2}[0-9]{3})(.*)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Loop through the lines of the response\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The file path for the csv file.\n",
    "#path2021 = 'data/cao2021_csv_' + nowstr + '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Keep track of how many courses we process.\n",
    "#no_lines = 0\n",
    "\n",
    "# Open the csv file for writing.\n",
    "#with open(path2021, 'w') as f:\n",
    "    # Write a header row.\n",
    "    #f.write(','.join(['code', 'title', 'pointsR1', 'pointsR2']) + '\\n')\n",
    "    # Loop through lines of the response.\n",
    "    #for line in resp.iter_lines():\n",
    "        # Decode the line, using the wrong encoding!\n",
    "        #dline = line.decode('cp1252')\n",
    "        # Match only the lines representing courses.\n",
    "        #if re_course.fullmatch(dline):\n",
    "            # Add one to the lines counter.\n",
    "            #no_lines = no_lines + 1\n",
    "            # The course code.\n",
    "            #course_code = dline[:5]\n",
    "            # The course title.\n",
    "            #course_title = dline[7:57].strip()\n",
    "            # Round one points.\n",
    "            #course_points = re.split(' +', dline[60:])\n",
    "            #if len(course_points) != 2:\n",
    "                #course_points = course_points[:2]\n",
    "            # Join the fields using a comma.\n",
    "            #linesplit = [course_code, course_title, course_points[0], course_points[1]]\n",
    "            # Rejoin the substrings with commas in between.\n",
    "            #f.write(','.join(linesplit) + '\\n')\n",
    "\n",
    "# Print the total number of processed lines.\n",
    "#print(f\"Total number of lines is {no_lines}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**NB:** it was verified as of 03/11/2021 that there were 949 courses exactly in the CAO 2021 points list.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2021 = pd.read_csv(path2021, encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2021 points from Excel (approach 2)\n",
    "---\n",
    "Since initial data scrape, CAO website was updated to provide 2021 points in xlsx format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 2021 CAO points:\n",
    "url2021 = 'http://www2.cao.ie/points/CAOPointsCharts2021.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Save Original File\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a file path for the original data.\n",
    "pathxlsx = 'data/cao2021_' + nowstr + '.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlrq.urlretrieve(url2021, pathxlsx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Load Spreadsheet using pandas\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and parse the excel spreadsheet.\n",
    "df2021 = pd.read_excel(url2021, skiprows=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only want the level 8 courses\n",
    "df2021 = df2021[df2021['Course Level'] == 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a file path for the pandas data.\n",
    "path2021 = 'data/cao2021_' + nowstr + '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pandas data frame to disk.\n",
    "df2021.to_csv(path2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2020 Points\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 2020 CAO points [7]:\n",
    "url2020 = 'http://www2.cao.ie/points/CAOPointsCharts2020.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Save Original File\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a file path for the original data.\n",
    "pathxlsx = 'data/cao2020_' + nowstr + '.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlrq.urlretrieve(url2020, pathxlsx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Load Spreadsheet using pandas\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and parse the excel spreadsheet.\n",
    "df2020 = pd.read_excel(url2020, skiprows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"#+matric\" from pandas df to help us out further on.\n",
    "# code adapted from GeekForGeeks [8]: \n",
    "#df2020['R1 POINTS'] = df2020['R1 POINTS'].replace({'[#+matric]':'0'}, regex=True)\n",
    "#df2020['R1 POINTS'] = df2020['R1 POINTS'].replace({'AQA':'0'}, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a file path for the pandas data.\n",
    "path2020 = 'data/cao2020_' + nowstr + '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pandas data frame to disk.\n",
    "df2020.to_csv(path2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2019 Points\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 2019 CAO points [9]:\n",
    "df2019 = pd.read_excel('data/cao2019_20211230_edited.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## concat and join\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses2021 = df2021[['Course Code', 'Course Title', 'HEI', 'R1 Points', 'R2 Points ']]\n",
    "courses2021.columns = ['Course Code', 'Course Title', 'HEI', 'R1 Points 2021', 'R2 Points 2021']\n",
    "courses2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses2020 = df2020[['COURSE CODE2','COURSE TITLE', 'HEI', 'R1 POINTS', 'R2 POINTS']]\n",
    "courses2020.columns = ['Course Code', 'Course Title', 'HEI', 'R1 Points 2020', 'R2 Points 2020']\n",
    "courses2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses2019 = df2019[['code', 'course', 'HEI', 'points']]\n",
    "courses2019.columns = ['Course Code', 'Course Title', 'HEI', 'R1 Points 2019']\n",
    "courses2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allcourses = pd.concat([courses2021, courses2020, courses2019], ignore_index=True)\n",
    "allcourses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allcourses.sort_values('Course Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allcourses.loc[175]['Course Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allcourses.loc[949]['Course Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds all extra copies of duplicated rows.\n",
    "allcourses[allcourses.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a copy of the data frame with duplciates removed.\n",
    "allcourses.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds all extra copies of duplicated rows.\n",
    "allcourses[allcourses.duplicated(subset=['Course Code'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a copy of the data frame with duplicates removed - based only on code.\n",
    "allcourses.drop_duplicates(subset=['Course Code'], inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allcourses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Join to the points\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the index to the code column.\n",
    "#df2021.set_index('Course Code', inplace=True)\n",
    "#df2021.columns = ['Course Title', 'R1 Points', 'R2 Points']\n",
    "#df2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the index to the code column.\n",
    "#allcourses.set_index('code', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allcourses = allcourses.join(df2021[['points_r1_2021', 'points_r2_2021']])\n",
    "#allcourses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2020_r1 = df2020[['COURSE CODE2', 'R1 POINTS']]\n",
    "#df2020_r1.columns = ['code', 'points_r1_2020']\n",
    "#df2020_r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the index to the code column.\n",
    "#df2020_r1.set_index('code', inplace=True)\n",
    "#df2020_r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join 2020 points to allcourses.\n",
    "#allcourses = allcourses.join(df2020_r1)\n",
    "#allcourses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join 2020 round 2 points \n",
    "#df2020_r2 = df2020[['COURSE CODE2', 'R2 POINTS']]\n",
    "#df2020_r2.columns = ['code', 'points_r2_2020']\n",
    "#df2020_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set the index to the code column.\n",
    "#df2020_r2.set_index('code', inplace=True)\n",
    "#df2020_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join 2020 round 2 points to allcourses.\n",
    "#allcourses = allcourses.join(df2020_r2)\n",
    "#allcourses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2019_r1 = df2019[['code', 'points']]\n",
    "#df2019_r1.columns = ['code', 'points_r1_2019']\n",
    "#df2019_r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the index to the code column.\n",
    "#df2019_r1.set_index('code', inplace=True)\n",
    "#df2019_r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join 2019 points to allcourses.\n",
    "#allcourses = allcourses.join(df2019_r1)\n",
    "#allcourses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NA with 0\n",
    "allcourses.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove # and * symbols from df.\n",
    "# Code adapted from StackOverflow [10]:\n",
    "\n",
    "cols_to_check = ['R1 Points 2021', 'R2 Points 2021', 'R1 Points 2020', 'R2 Points 2020', 'R1 Points 2019']\n",
    "#allcourses[cols_to_check] = allcourses[cols_to_check].replace({'[#,*]':''}, regex=True)\n",
    "allcourses[cols_to_check] = allcourses[cols_to_check].replace('[A-Z.#*+a-z]', '', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all course to CSV so we can check the stats. \n",
    "allcourses.to_csv(\"allcourses.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# see data type\n",
    "allcourses.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data type is appearing as \"object\" for each of our variables which is text or mixed numeric values. we need to change these to a numeric type which we can do using pandas.to_numeric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert argument to numeric type [10]\n",
    "allcourses['R1 Points 2021'] = pd.to_numeric(allcourses['R1 Points 2021'],errors = 'coerce')\n",
    "allcourses['R2 Points 2021'] = pd.to_numeric(allcourses['R2 Points 2021'],errors = 'coerce')\n",
    "allcourses['R1 Points 2020'] = pd.to_numeric(allcourses['R1 Points 2020'],errors = 'coerce')\n",
    "allcourses['R2 Points 2020'] = pd.to_numeric(allcourses['R2 Points 2020'],errors = 'coerce')\n",
    "allcourses['R1 Points 2019'] = pd.to_numeric(allcourses['R1 Points 2019'],errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allcourses.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values are now floating point numbers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe the Data\n",
    "\n",
    "We can use df.describe() to view some basic statistical details of the data set, inlcuding the percentile, mean and standard deviation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allcourses.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "---\n",
    "We now have a Pandas dataframe titled \"allcourses\", which shows data for the following variables:\n",
    "* Course Code \n",
    "* Course Title \n",
    "* Higher Education Institue (\"HEI\") \n",
    "* Round 1 points for 2021, 2020 and 2019 \n",
    "* Round 2 points for 2021 and 2020 only (as Round 2 points are not available for 2019). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allcourses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(allcourses['HEI'],\n",
    "         facecolor='peru',\n",
    "         edgecolor='blue',\n",
    "         bins = 10)\n",
    "\n",
    "#plt.hist(allcourses['R2 Points 2020'],\n",
    "#        facecolor='red',\n",
    "#        edgecolor='maroon',\n",
    "#        bins=8,\n",
    "#        alpha=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to see what the data looks like, I've used seaborn pairplot to plot the pairwise relationships in the dataset. This function creates a grid of axes that shows the relationships between each of the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot univariate or bivariate distributions using seaborn kernel density estimation [11]\n",
    "# Change style to seaborn\n",
    "plt.style.use('seaborn')\n",
    "sns.kdeplot(allcourses['R1 Points 2021'], label='R1 2021')\n",
    "sns.kdeplot(allcourses['R1 Points 2020'], label='R1 2020')\n",
    "sns.kdeplot(allcourses['R1 Points 2019'], label='R1 2019')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(allcourses['R1 Points 2021'], label='R1 2021')\n",
    "sns.histplot(allcourses['R2 Points 2021'], label='R2 2021')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(allcourses['HEI'], label='HEI')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion / Next-steps\n",
    "I will conclude by stating that I have realised that in order to carry out more meaningful analysis, I will need to also bring the college/institution names. As it stands, my dataframe is too large to produce graphs showing the individual course point movements (given there are 1651 courses in total). If I were to bring in the college names I  could show overall trends between the colleges. Should I be in a position to provide a further commit following tonight's deadline, I will strive to carry out this next step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## References\n",
    "1. https://www.w3schools.com/python/python_regex.asp\n",
    "2. https://www.w3schools.com/python/module_requests.asp\n",
    "3. https://www.w3schools.com/python/python_datetime.asp\n",
    "4. https://www.w3schools.com/python/pandas/pandas_intro.asp\n",
    "5. https://www.geeksforgeeks.org/python-urllib-module/\n",
    "6. http://www.cao.ie/index.php?page=points&p=2021\n",
    "7 https://www.cao.ie/index.php?page=points&p=2020\n",
    "8. https://www.geeksforgeeks.org/pandas-remove-special-characters-from-column-names/\n",
    "9. https://www.cao.ie/index.php?page=points&p=2019\n",
    "10. https://stackoverflow.com/questions/42135409/removing-a-character-from-entire-data-frame\n",
    "10. https://pandas.pydata.org/docs/reference/api/pandas.to_numeric.html\n",
    "11. https://seaborn.pydata.org/generated/seaborn.kdeplot.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
